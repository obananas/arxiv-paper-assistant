import requests
import datetime
import smtplib
import email.utils
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from openai import OpenAI
import xml.etree.ElementTree as ET
import os
import csv
from urllib.parse import quote_plus


def get_yesterday_utc():
    """
    è·å–UTCæ—¶é—´çš„å‰ä¸€å¤©æ—¥æœŸ
    """
    today = datetime.datetime.now(datetime.timezone.utc)
    yesterday = today - datetime.timedelta(days=1)
    return yesterday.strftime('%Y-%m-%d')


def search_arxiv_papers(search_term, target_date, max_results=50):
    """
    åœ¨arXivæŒ‰å…³é”®è¯æœç´¢æŒ‡å®šæ—¥æœŸçš„è®¡ç®—æœºç§‘å­¦é¢†åŸŸè®ºæ–‡
    æ”¹è¿›ç‚¹ï¼šURLç¼–ç ã€å¸ƒå°”é€»è¾‘ä¼˜åŒ–ã€è°ƒè¯•è¾“å‡º
    """
    papers = []
    base_url = 'http://export.arxiv.org/api/query?'
    
    try:
        # ç¼–ç æœç´¢è¯å¹¶æ„å»ºæŸ¥è¯¢
        encoded_term = quote_plus(search_term)
        search_query = (
            f'search_query=(ti:{encoded_term}+OR+abs:{encoded_term})'
            f'+AND+cat:cs.*'
            f'&start=0&max_results={max_results}'
            f'&sortBy=submittedDate&sortOrder=descending'
        )
        full_url = base_url + search_query
        print(f"DEBUG - æœç´¢URL: {full_url}")  # è°ƒè¯•è¾“å‡º

        response = requests.get(full_url, timeout=30)
        response.raise_for_status()  # è§¦å‘HTTPé”™è¯¯å¼‚å¸¸

        # è§£æXML
        root = ET.fromstring(response.content)
        namespaces = {
            'atom': 'http://www.w3.org/2005/Atom',
            'arxiv': 'http://arxiv.org/schemas/atom'
        }

        entries = root.findall('.//atom:entry', namespaces)
        if not entries:
            print(f"æœªæ‰¾åˆ°ä¸ '{search_term}' åŒ¹é…çš„æ¡ç›®")
            return []

        for entry in entries:
            # æå–å‘å¸ƒæ—¥æœŸ
            pub_date_str = entry.find('./atom:published', namespaces).text
            pub_date = datetime.datetime.strptime(
                pub_date_str, "%Y-%m-%dT%H:%M:%SZ").strftime("%Y-%m-%d")
            
            if pub_date != target_date:
                continue  # è·³è¿‡éç›®æ ‡æ—¥æœŸçš„è®ºæ–‡

            # æå–è®ºæ–‡ä¿¡æ¯
            title = entry.find('./atom:title', namespaces).text.strip()
            summary = entry.find('./atom:summary', namespaces).text.strip()
            url = entry.find('./atom:id', namespaces).text.strip()
            arxiv_id = url.split('/')[-1]
            
            authors = [
                author.find('./atom:name', namespaces).text.strip()
                for author in entry.findall('./atom:author', namespaces)
            ]
            
            categories = [
                category.get('term')
                for category in entry.findall('./atom:category', namespaces)
            ]
            
            comments_elem = entry.find('./arxiv:comment', namespaces)
            comments = comments_elem.text.strip() if comments_elem is not None else None

            papers.append({
                'title': title,
                'authors': authors,
                'url': url,
                'arxiv_id': arxiv_id,
                'pub_date': pub_date,
                'summary': summary,
                'categories': categories,
                'comments': comments,
            })

        print(f"æ‰¾åˆ° {len(papers)} ç¯‡ç¬¦åˆæ—¥æœŸè¦æ±‚çš„è®ºæ–‡")
        return papers

    except requests.exceptions.RequestException as e:
        print(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
        return []
    except ET.ParseError as e:
        print(f"XMLè§£æå¤±è´¥: {str(e)}")
        return []


def process_with_openai(text, prompt_template, openai_api_key, model_name="gpt-3.5-turbo", api_base=None):
    """æ•´åˆä¼˜åŒ–çš„AIå¤„ç†å‡½æ•°"""
    try:
        prompt = prompt_template.format(text=text)
        client = OpenAI(
            api_key=openai_api_key,
            base_url=api_base if api_base else "https://api.openai.com/v1"
        )
        
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,  # é™ä½éšæœºæ€§
            max_tokens=2000    # æ§åˆ¶è¾“å‡ºé•¿åº¦
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"AIå¤„ç†å¤±è´¥: {str(e)}")
        return None


def format_paper_for_email(paper):
    """æ”¹è¿›çš„é‚®ä»¶æ ¼å¼åŒ–å‡½æ•°"""
    SEPARATOR = "\n" + "-"*70 + "\n"
    content = SEPARATOR
    content += f"ğŸ“„ æ ‡é¢˜: {paper['title']}\n"
    content += f"ğŸ‘¥ ä½œè€…: {', '.join(paper['authors'])}\n"
    content += f"ğŸ·ï¸ åˆ†ç±»: {', '.join(paper.get('categories', ['N/A']))}\n"
    content += f"ğŸ“… æ—¥æœŸ: {paper['pub_date']}\n"
    
    if paper.get('comments'):
        content += f"ğŸ’¬ è¯„è®º: {paper['comments']}\n"
    
    content += f"ğŸ”— é“¾æ¥: https://arxiv.org/abs/{paper['arxiv_id']}\n"
    content += f"ğŸ“„ PDF: https://arxiv.org/pdf/{paper['arxiv_id']}.pdf\n\n"
    
    # åŠ¨æ€æ·»åŠ AIå¤„ç†å†…å®¹
    for field in ['contribution', 'summary_zh']:
        if paper.get(field):
            header = "è´¡çŒ®è¦ç‚¹" if field == 'contribution' else "ä¸­æ–‡æ‘˜è¦"
            content += f"ğŸŒŸ {header}:\n{paper[field]}\n\n"
    
    content += "ğŸ“œ åŸå§‹æ‘˜è¦:\n" + paper['summary'] + "\n"
    return content + SEPARATOR


def send_email(subject, content, sender_info, receiver_emails):
    """æ”¹è¿›çš„é‚®ä»¶å‘é€å‡½æ•°"""
    msg = MIMEMultipart()
    msg['From'] = email.utils.formataddr((sender_info['name'], sender_info['email']))
    msg['To'] = ', '.join(receiver_emails) if isinstance(receiver_emails, list) else receiver_emails
    msg['Subject'] = Header(subject, 'utf-8')
    msg.attach(MIMEText(content, 'plain', 'utf-8'))

    try:
        with smtplib.SMTP_SSL(sender_info['smtp_server'], sender_info['smtp_port']) as server:
            server.login(sender_info['email'], sender_info['password'])
            server.sendmail(sender_info['email'], receiver_emails, msg.as_string())
        print(f"é‚®ä»¶æˆåŠŸå‘é€è‡³ {msg['To']}")
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥: {str(e)}")


if __name__ == '__main__':
    # é…ç½®åŠ è½½
    config = {
        'sender': {
            'email': os.getenv("SENDER_EMAIL", "your_email@qq.com"),
            'password': os.getenv("SENDER_PASSWORD", "your_app_password"),
            'name': os.getenv("SENDER_NAME", "arXivè®ºæ–‡åŠ©æ‰‹"),
            'smtp_server': os.getenv("SMTP_SERVER", "smtp.qq.com"),
            'smtp_port': int(os.getenv("SMTP_PORT", 465))
        },
        'openai': {
            'api_key': os.getenv("OPENAI_API_KEY", "your_api_key"),
            'model': os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
            'api_base': os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
        },
        'search_terms': [],
        'receiver_emails': list(filter(None, os.getenv("RECEIVER_EMAILS", "").split(','))),
        'max_results': int(os.getenv("MAX_RESULTS", 50))
    }

    # è§£æå…³é”®è¯ï¼ˆæ”¯æŒå¸¦ç©ºæ ¼å’Œå¼•å·ï¼‰
    try:
        reader = csv.reader([os.getenv("SEARCH_TERMS", 'transformer,"large language model"')])
        config['search_terms'] = next(reader)
    except Exception as e:
        print(f"å…³é”®è¯è§£æå¤±è´¥: {str(e)}")
        config['search_terms'] = ['transformer', 'large language model']

    # ä¸»é€»è¾‘
    target_date = get_yesterday_utc()
    all_papers = {}
    
    for term in config['search_terms']:
        print(f"\nğŸ” æ­£åœ¨æœç´¢: {term}")
        papers = search_arxiv_papers(term, target_date, config['max_results'])
        
        for paper in papers:
            # AIå¤„ç†
            paper['summary_zh'] = process_with_openai(
                paper['summary'],
                "å°†ä»¥ä¸‹è‹±æ–‡è®ºæ–‡æ‘˜è¦ç¿»è¯‘ä¸ºä¸­æ–‡ï¼Œä¿æŒä¸“ä¸šæœ¯è¯­ä¸å˜:\n{text}",
                config['openai']['api_key'],
                config['openai']['model'],
                config['openai']['api_base']
            )
            
            paper['contribution'] = process_with_openai(
                paper['summary'],
                "ç”¨ä¸€å¥ä¸­æ–‡è¯´æ˜è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ï¼Œæ ¼å¼ï¼šæ–¹æ³•+æ•ˆæœ:\n{text}",
                config['openai']['api_key'],
                config['openai']['model'],
                config['openai']['api_base']
            )
            
            all_papers[paper['arxiv_id']] = paper

    # ç”Ÿæˆé‚®ä»¶å†…å®¹
    if not all_papers:
        email_content = f"ã€{target_date}ã€‘arXivè®ºæ–‡æ—¥æŠ¥\n\næœªæ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„è®ºæ–‡"
    else:
        email_content = f"ã€{target_date}ã€‘arXivè®ºæ–‡æ—¥æŠ¥\nå‘ç°{len(all_papers)}ç¯‡é‡è¦è®ºæ–‡\n\n"
        email_content += "\n".join([format_paper_for_email(p) for p in all_papers.values()])

    # å‘é€é‚®ä»¶
    if config['receiver_emails']:
        send_email(
            subject=f"arXivæ—¥æŠ¥ {target_date}",
            content=email_content,
            sender_info=config['sender'],
            receiver_emails=config['receiver_emails']
        )
    else:
        print("æœªé…ç½®æ¥æ”¶é‚®ç®±ï¼Œé‚®ä»¶æœªå‘é€")
